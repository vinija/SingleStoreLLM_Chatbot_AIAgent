{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec00bfd2",
   "metadata": {},
   "source": [
    "# Chatbot Agent\n",
    "\n",
    "This notebook demonstrates the implementation of a chatbot agent using transformers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d7e512-aca7-4153-8354-43a8272ef317",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T01:54:18.766861Z",
     "iopub.status.busy": "2024-07-29T01:54:18.766571Z",
     "iopub.status.idle": "2024-07-29T01:54:42.360451Z",
     "shell.execute_reply": "2024-07-29T01:54:42.359445Z",
     "shell.execute_reply.started": "2024-07-29T01:54:18.766837Z"
    },
    "language": "python"
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow\n",
    "!pip install transformers\n",
    "!pip install datasets\n",
    "!pip install torch\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8726e5-c546-48da-ada7-a8d95f66c825",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T02:22:45.940567Z",
     "iopub.status.busy": "2024-07-29T02:22:45.940273Z",
     "iopub.status.idle": "2024-07-29T02:25:30.440158Z",
     "shell.execute_reply": "2024-07-29T02:25:30.438950Z",
     "shell.execute_reply.started": "2024-07-29T02:22:45.940539Z"
    },
    "language": "python"
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "class CustomerSupportAgent:\n",
    "    \"\"\"\n",
    "    A customer support AI agent that uses a language model to interact with users,\n",
    "    providing responses based on user queries. The agent handles perception,\n",
    "    decision-making, and action-taking to simulate a conversational support experience.\n",
    "    \"\"\"\n",
    "    def __init__(self, model_name=\"EleutherAI/gpt-neo-125M\"):\n",
    "        \"\"\"\n",
    "        Initializes the CustomerSupportAgent with a specified language model.\n",
    "\n",
    "        Parameters:\n",
    "        - model_name (str): The name of the pre-trained language model to use.\n",
    "        \"\"\"\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        self.chatbot = pipeline(\"text-generation\", model=self.model, tokenizer=self.tokenizer)\n",
    "        self.conversation_history = []\n",
    "\n",
    "    def perceive(self, user_input):\n",
    "        \"\"\"\n",
    "        Processes the user's input and updates the conversation history.\n",
    "\n",
    "        Parameters:\n",
    "        - user_input (str): The user's input message.\n",
    "\n",
    "        Returns:\n",
    "        - str: The processed user input, converted to lowercase.\n",
    "        \"\"\"\n",
    "        self.conversation_history.append(f\"User: {user_input}\")\n",
    "        return user_input.lower()\n",
    "\n",
    "    def decide(self, user_input):\n",
    "        \"\"\"\n",
    "        Generates a response based on the user's input and conversation history.\n",
    "\n",
    "        Parameters:\n",
    "        - user_input (str): The processed user input.\n",
    "\n",
    "        Returns:\n",
    "        - str: The generated response from the language model.\n",
    "        \"\"\"\n",
    "        prompt = \"\\n\".join(self.conversation_history) + \"\\nAssistant:\"\n",
    "        inputs = self.tokenizer(prompt, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "        output = self.model.generate(**inputs, max_new_tokens=50, do_sample=True, temperature=0.7)\n",
    "        return self.tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    def act(self, response):\n",
    "        \"\"\"\n",
    "        Finalizes the response, appends it to the conversation history, and returns it.\n",
    "\n",
    "        Parameters:\n",
    "        - response (str): The generated response from the language model.\n",
    "\n",
    "        Returns:\n",
    "        - str: The final response to be provided to the user.\n",
    "        \"\"\"\n",
    "        self.conversation_history.append(f\"Assistant: {response}\")\n",
    "        return response\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Runs the interaction loop, allowing continuous conversation with the user.\n",
    "        The loop terminates when the user inputs 'exit' or 'quit'.\n",
    "        \"\"\"\n",
    "        print(\"Assistant: Hello! How can I assist you today?\")\n",
    "        while True:\n",
    "            user_input = input(\"You: \")\n",
    "            if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "                print(\"Assistant: Goodbye!\")\n",
    "                break\n",
    "            perceived_input = self.perceive(user_input)\n",
    "            response = self.decide(perceived_input)\n",
    "            print(f\"Assistant: {self.act(response)}\")\n",
    "\n",
    "# Running the AI agent\n",
    "agent = CustomerSupportAgent()\n",
    "agent.run()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5016de53-f12c-406b-a63f-5a3d038fb097",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupyterlab": {
   "notebooks": {
    "version_major": 6,
    "version_minor": 4
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "singlestore_cell_default_language": "python",
  "singlestore_connection": {
   "connectionID": "dbefb17b-029c-485c-8845-fb540cee52f7",
   "defaultDatabase": "database_7b9af"
  },
  "singlestore_row_limit": 300
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
